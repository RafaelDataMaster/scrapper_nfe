# üéØ Exemplos Pr√°ticos - Docker NFSe Scrapper

Guia r√°pido com comandos copy-paste para opera√ß√µes comuns.

---

## üöÄ Setup Inicial (Primeira Vez)

### Windows

```powershell
# 1. Clone o reposit√≥rio (se ainda n√£o tiver)
git clone <seu-repo-url>
cd scrapper

# 2. Execute o setup autom√°tico
setup-docker.bat

# 3. Edite o .env com suas credenciais (abre no Notepad)
notepad .env

# 4. Build e teste
docker-compose build
docker-compose run --rm scrapper python scripts/test_docker_setup.py
```

### Linux/Mac

```bash
# 1. Clone o reposit√≥rio
git clone <seu-repo-url>
cd scrapper

# 2. Execute o setup autom√°tico
chmod +x setup-docker.sh
./setup-docker.sh

# 3. Edite o .env
nano .env  # ou vim, code, etc.

# 4. Build e teste
docker-compose build
docker-compose run --rm scrapper python scripts/test_docker_setup.py
```

---

## üìß Configura√ß√£o do Email

### Gmail com 2FA (Recomendado)

```bash
# 1. Gere uma senha de aplicativo:
#    https://myaccount.google.com/apppasswords
#
# 2. Configure no .env:
EMAIL_HOST=imap.gmail.com
EMAIL_USER=seu_email@gmail.com
EMAIL_PASS=xxxx xxxx xxxx xxxx  # Senha de app (com espa√ßos mesmo!)
EMAIL_FOLDER=INBOX
```

### Outlook / Office 365

```bash
EMAIL_HOST=outlook.office365.com
EMAIL_USER=seu_email@outlook.com
EMAIL_PASS=sua_senha_de_app
EMAIL_FOLDER=INBOX
```

### Outros Provedores

```bash
# Yahoo
EMAIL_HOST=imap.mail.yahoo.com

# ProtonMail (precisa do Bridge)
EMAIL_HOST=127.0.0.1
EMAIL_PORT=1143

# Servidor customizado
EMAIL_HOST=mail.suaempresa.com.br
```

---

## ‚ñ∂Ô∏è Execu√ß√£o

### Modo 1: Execu√ß√£o Manual (Uma Vez)

**Use quando:** Quer processar manualmente, testar, ou debugar.

```bash
# Executa uma vez e mostra output no terminal
docker-compose run --rm scrapper

# Com logs mais verbosos
docker-compose run --rm scrapper python -u run_ingestion.py
```

**Output esperado:**

```
üìÇ Diret√≥rio tempor√°rio criado: /app/temp_email
üîå Conectando a imap.gmail.com como scrapper.nsfe@gmail.com...
üîç Buscando e-mails com assunto: 'ENC'...
üì¶ 5 anexo(s) encontrado(s). Iniciando processamento...
  Processing: nota_fiscal_123.pdf...
  Processing: boleto_456.pdf...
‚úÖ Processamento conclu√≠do! Relat√≥rios salvos em data/output/
```

### Modo 2: Execu√ß√£o Cont√≠nua (Cron)

**Use quando:** Quer que rode automaticamente de X em X minutos.

```bash
# Inicia em background (a cada 30 minutos)
docker-compose up -d scrapper-cron

# Verifica se est√° rodando
docker-compose ps

# Acompanha logs em tempo real
docker-compose logs -f scrapper-cron

# Para de acompanhar: Ctrl+C (container continua rodando)
```

**Para modificar o intervalo**, edite o `docker-compose.yml`:

```yaml
# A cada 15 minutos (900 segundos)
command: sh -c "while true; do python run_ingestion.py && sleep 900; done"

# A cada 1 hora (3600 segundos)
command: sh -c "while true; do python run_ingestion.py && sleep 3600; done"

# A cada 6 horas
command: sh -c "while true; do python run_ingestion.py && sleep 21600; done"
```

Depois de editar:

```bash
docker-compose down
docker-compose up -d scrapper-cron
```

### Modo 3: Cron do Sistema (Hor√°rios Espec√≠ficos)

**Use quando:** Quer executar em hor√°rios fixos (ex: 9h e 18h).

**Linux (crontab):**

```bash
# Editar crontab
crontab -e

# Adicionar (executa √†s 9h e 18h):
0 9,18 * * * cd /caminho/para/scrapper && docker-compose run --rm scrapper >> /var/log/scrapper.log 2>&1

# Executa de hora em hora:
0 * * * * cd /caminho/para/scrapper && docker-compose run --rm scrapper

# Executa a cada 30 minutos:
*/30 * * * * cd /caminho/para/scrapper && docker-compose run --rm scrapper
```

**Windows (Task Scheduler):**

```powershell
# Criar script run_scrapper.bat:
@echo off
cd C:\Users\rafael.ferreira\Documents\scrapper
docker-compose run --rm scrapper >> logs\scrapper.log 2>&1

# Depois:
# 1. Abra o Task Scheduler (Agendador de Tarefas)
# 2. Criar Tarefa B√°sica
# 3. Trigger: Diariamente √†s 9h e 18h
# 4. A√ß√£o: Iniciar programa ‚Üí run_scrapper.bat
```

---

## üìä Monitoramento

### Ver Logs

```bash
# Logs em tempo real (Ctrl+C para sair)
docker-compose logs -f scrapper-cron

# √öltimas 50 linhas
docker-compose logs --tail=50 scrapper-cron

# Logs de um per√≠odo espec√≠fico
docker-compose logs --since="2025-12-18T09:00:00" scrapper-cron

# Exportar logs para arquivo
docker-compose logs --no-color scrapper-cron > logs_$(date +%Y%m%d).txt
```

### Ver Status

```bash
# Containers ativos
docker-compose ps

# Recursos (CPU, RAM, Rede)
docker stats nfse-scrapper-cron

# Informa√ß√µes detalhadas
docker inspect nfse-scrapper-cron
```

### Healthcheck

```bash
# Verifica se o Tesseract est√° OK (healthcheck autom√°tico)
docker-compose exec scrapper-cron tesseract --version

# Testa manualmente
docker-compose exec scrapper-cron python -c "
import pytesseract
from config import settings
print('Tesseract:', pytesseract.get_tesseract_version())
print('Config:', settings.TESSERACT_CMD)
"
```

---

## üß™ Testes e Valida√ß√£o

### Teste Completo de Setup

```bash
docker-compose run --rm scrapper python scripts/test_docker_setup.py
```

### Validar Regras de Extra√ß√£o

```bash
# Valida regras com PDFs em failed_cases_pdf/
docker-compose run --rm scrapper python scripts/validate_extraction_rules.py
```

### Inspecionar PDF

```bash
docker-compose run --rm scrapper python scripts/inspect_pdf.py arquivo.pdf
```

### Valida√ß√£o Batch com Correla√ß√£o

```bash
docker-compose run --rm scrapper python scripts/validate_extraction_rules.py --batch-mode --apply-correlation
```

### Teste de Conex√£o Email (Interativo)

```bash
docker-compose run --rm scrapper python -c "
from ingestors.imap import ImapIngestor
from config import settings

print('Testando conex√£o...')
ingestor = ImapIngestor(
    host=settings.EMAIL_HOST,
    user=settings.EMAIL_USER,
    password=settings.EMAIL_PASS,
    folder=settings.EMAIL_FOLDER
)

try:
    ingestor.connect()
    print('‚úÖ Conex√£o OK!')
    print(f'Pasta: {settings.EMAIL_FOLDER}')
except Exception as e:
    print(f'‚ùå Erro: {e}')
"
```

---

## üîß Manuten√ß√£o

### Atualizar C√≥digo

```bash
# 1. Baixar atualiza√ß√µes
git pull origin main

# 2. Parar containers
docker-compose down

# 3. Rebuild (sem cache para for√ßar atualiza√ß√£o)
docker-compose build --no-cache

# 4. Subir novamente
docker-compose up -d scrapper-cron
```

### Limpar Dados Tempor√°rios

```bash
# Limpa temp_email (√© limpo automaticamente a cada execu√ß√£o)
docker-compose run --rm scrapper rm -rf temp_email/*

# Limpa logs antigos
docker-compose run --rm scrapper find /app -name "*.log" -mtime +30 -delete
```

### Backup de Dados

```bash
# Backup manual
tar -czf backup_$(date +%Y%m%d_%H%M%S).tar.gz data/

# Script de backup autom√°tico (Linux cron)
# Adicione ao crontab:
0 2 * * * cd /path/to/scrapper && tar -czf backup_$(date +\%Y\%m\%d).tar.gz data/ && find . -name "backup_*.tar.gz" -mtime +7 -delete
```

### Reset Completo

```bash
# Para tudo
docker-compose down

# Remove volumes (‚ö†Ô∏è DELETA DADOS!)
docker-compose down -v

# Remove imagens
docker rmi $(docker images -q 'scrapper*')

# Rebuild do zero
docker-compose build --no-cache
docker-compose up -d scrapper-cron
```

---

## üêö Acesso ao Container

### Shell Interativo

```bash
# Acessa bash do container em execu√ß√£o
docker-compose exec scrapper-cron bash

# Dentro do container, voc√™ pode:
ls data/output/           # Ver arquivos gerados
cat data/output/relatorio_nfse.csv  # Ver conte√∫do
python run_ingestion.py   # Executar manualmente
tesseract --version       # Verificar Tesseract
```

### Executar Comandos One-Off

```bash
# Lista arquivos de output
docker-compose exec scrapper-cron ls -lh data/output/

# Conta quantos PDFs foram processados
docker-compose exec scrapper-cron wc -l data/output/relatorio_nfse.csv

# Verifica espa√ßo em disco
docker-compose exec scrapper-cron df -h

# Ver vari√°veis de ambiente
docker-compose exec scrapper-cron env | grep EMAIL
```

---

## üìÅ Acessar Dados Gerados

### No Host (Seu PC/Servidor)

Os dados s√£o automaticamente sincronizados via volumes:

```bash
# Windows
dir data\output\
type data\output\relatorio_nfse.csv

# Linux/Mac
ls -lh data/output/
cat data/output/relatorio_nfse.csv
```

### Copiar do Container para Host

```bash
# Se por algum motivo n√£o estiver usando volumes:
docker cp nfse-scrapper-cron:/app/data/output/relatorio_nfse.csv ./local_copy.csv
```

### Copiar do Host para Container

```bash
# Para testar um PDF espec√≠fico:
docker cp meu_pdf_teste.pdf nfse-scrapper-cron:/app/failed_cases_pdf/
docker-compose exec scrapper-cron python scripts/validate_extraction_rules.py
```

---

## üö® Troubleshooting R√°pido

### Container n√£o inicia

```bash
# Ver logs de erro
docker-compose logs scrapper-cron

# Rebuild for√ßado
docker-compose build --no-cache
docker-compose up scrapper-cron  # Sem -d para ver output
```

### Erro "Tesseract not found"

```bash
# Verifica instala√ß√£o
docker-compose run --rm scrapper which tesseract
docker-compose run --rm scrapper tesseract --version

# Se n√£o aparecer, rebuild:
docker-compose build --no-cache
```

### Erro "Unable to get page count"

```bash
# Verifica Poppler
docker-compose run --rm scrapper which pdfinfo
docker-compose run --rm scrapper pdfinfo -v

# Se n√£o aparecer, rebuild:
docker-compose build --no-cache
```

### Email n√£o conecta

```bash
# Verifica credenciais
cat .env | grep EMAIL

# Testa dentro do container
docker-compose run --rm scrapper python -c "from config import settings; print(settings.EMAIL_HOST, settings.EMAIL_USER, settings.EMAIL_PASS[:4]+'***')"

# Testa conex√£o
docker-compose run --rm scrapper python -c "
from ingestors.imap import ImapIngestor
from config import settings
i = ImapIngestor(settings.EMAIL_HOST, settings.EMAIL_USER, settings.EMAIL_PASS)
i.connect()
print('OK!')
"
```

### PDFs n√£o sendo extra√≠dos

```bash
# Ativa modo debug
docker-compose run --rm scrapper python -c "
from core.processor import BaseInvoiceProcessor
processor = BaseInvoiceProcessor()
result = processor.process('failed_cases_pdf/seu_pdf.pdf')
print(result.__dict__)
"

# Testa extra√ß√£o manual
docker-compose run --rm scrapper python scripts/validate_extraction_rules.py
```

---

## üìà Otimiza√ß√£o de Performance

### Aumentar Recursos

Edite `docker-compose.yml`:

```yaml
deploy:
    resources:
        limits:
            cpus: "4.0" # Era 2.0, agora 4.0
            memory: 4G # Era 2G, agora 4G
```

Depois:

```bash
docker-compose down
docker-compose up -d scrapper-cron
```

### Paraleliza√ß√£o (Para MUITOS Emails)

Modifique `run_ingestion.py` para processar em paralelo:

```python
from concurrent.futures import ThreadPoolExecutor

# ...
with ThreadPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(processor.process, file_paths))
```

Ou rode m√∫ltiplas inst√¢ncias:

```bash
# docker-compose.yml - adicione:
scrapper-cron-2:
  <<: *scrapper-cron  # Refer√™ncia
  container_name: nfse-scrapper-cron-2

scrapper-cron-3:
  <<: *scrapper-cron
  container_name: nfse-scrapper-cron-3
```

---

## üéì Dicas Avan√ßadas

### Integra√ß√£o com CI/CD (GitHub Actions)

Crie `.github/workflows/docker.yml`:

```yaml
name: Build and Push Docker

on:
    push:
        branches: [main]

jobs:
    build:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v3

            - name: Build image
              run: docker-compose build

            - name: Run tests
              run: docker-compose run --rm scrapper python scripts/test_docker_setup.py

            - name: Push to Docker Hub
              run: |
                  echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin
                  docker-compose push
```

### Monitoramento com Prometheus

Adicione ao `docker-compose.yml`:

```yaml
prometheus:
    image: prom/prometheus
    volumes:
        - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
        - "9090:9090"

grafana:
    image: grafana/grafana
    ports:
        - "3000:3000"
```

### Alertas por Email/Slack

Instale `requests`:

```bash
# Adicione ao requirements.txt
requests

# No run_ingestion.py, adicione:
import requests

def notify_slack(message):
    webhook_url = os.getenv('SLACK_WEBHOOK')
    if webhook_url:
        requests.post(webhook_url, json={"text": message})

# Use:
notify_slack(f"‚úÖ Processados {len(anexos)} anexos com sucesso!")
```

---

## üÜò Ajuda

**Documenta√ß√£o Completa:** [README-DOCKER.md](README-DOCKER.md)

**An√°lise do Projeto:** [DOCKER-MIGRATION.md](DOCKER-MIGRATION.md)

**Issues Comuns:** Veja se√ß√£o Troubleshooting no README-DOCKER.md

**Suporte:** rafael.ferreira@soumaster.com.br

---

**√öltima atualiza√ß√£o:** 18/12/2025
