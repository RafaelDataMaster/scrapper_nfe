"""
Gerenciador de Embeddings usando sentence-transformers.

CONCEITO:
=========
Embedding = transformar texto em um vetor num√©rico de tamanho fixo.
Textos semanticamente similares ter√£o vetores "pr√≥ximos" no espa√ßo.

MODELO USADO:
=============
all-MiniLM-L6-v2
- Tamanho: ~80MB (baixa na primeira execu√ß√£o)
- Dimens√µes: 384 (cada texto vira um vetor de 384 n√∫meros)
- Velocidade: Muito r√°pido, funciona bem em CPU
- Qualidade: Boa para textos em ingl√™s/portugu√™s t√©cnico

COMO FUNCIONA:
==============
1. O modelo foi pr√©-treinado em milh√µes de pares de texto
2. Ele aprendeu que "PDF protegido" e "arquivo com senha" s√£o similares
3. Quando voc√™ passa um texto, ele retorna um vetor que "representa" o significado
"""

from sentence_transformers import SentenceTransformer
from typing import List, Union
import numpy as np


class EmbeddingManager:
    """
    Gerencia a cria√ß√£o de embeddings para textos.

    Attributes:
        model: Modelo sentence-transformers carregado
        model_name: Nome do modelo usado
        embedding_dim: Dimens√£o dos vetores gerados (384 para MiniLM)

    Example:
        >>> em = EmbeddingManager()
        >>> vetor = em.embed("Como resolver PDF protegido?")
        >>> print(len(vetor))  # 384
    """

    # Modelo leve e eficiente - bom equil√≠brio qualidade/velocidade
    DEFAULT_MODEL = "all-MiniLM-L6-v2"

    def __init__(self, model_name: str = DEFAULT_MODEL):
        """
        Inicializa o gerenciador de embeddings.

        Args:
            model_name: Nome do modelo do HuggingFace a usar.
                       Default: all-MiniLM-L6-v2 (recomendado)

        Note:
            Na primeira execu√ß√£o, o modelo ser√° baixado (~80MB).
            Depois fica em cache local.
        """
        self.model_name = model_name
        print(f"üîÑ Carregando modelo de embeddings: {model_name}...")

        # SentenceTransformer carrega o modelo do HuggingFace
        # O modelo fica em cache em ~/.cache/huggingface/
        self.model = SentenceTransformer(model_name)

        # Dimens√£o do vetor de sa√≠da (384 para MiniLM)
        self.embedding_dim = self.model.get_sentence_embedding_dimension()
        print(f"‚úÖ Modelo carregado! Dimens√£o dos embeddings: {self.embedding_dim}")

    def embed(self, text: Union[str, List[str]]) -> np.ndarray:
        """
        Gera embedding(s) para texto(s).

        Args:
            text: String √∫nica ou lista de strings

        Returns:
            np.ndarray: Vetor(es) de embedding
                - Para string √∫nica: shape (embedding_dim,)
                - Para lista: shape (n_textos, embedding_dim)

        Example:
            >>> em = EmbeddingManager()
            >>> v1 = em.embed("PDF protegido")
            >>> v2 = em.embed("arquivo com senha")
            >>> # v1 e v2 ser√£o vetores "pr√≥ximos" no espa√ßo
        """
        # O modelo processa o texto e retorna o vetor
        # convert_to_numpy=True garante que retorna np.ndarray
        return self.model.encode(text, convert_to_numpy=True)
