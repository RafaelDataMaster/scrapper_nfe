"""
Script de validaÃ§Ã£o de regras de extraÃ§Ã£o para NFSe e Boletos.

Este script processa PDFs da pasta failed_cases_pdf e gera relatÃ³rios
detalhados separando sucessos e falhas, auxiliando no ajuste fino das regex.

âš ï¸ MODOS IMPORTANTES (MVP):
- Por padrÃ£o, IGNORA a validaÃ§Ã£o de prazo de 4 dias Ãºteis (Ãºtil para documentos antigos)
    Para validar prazo: python scripts/validate_extraction_rules.py --validar-prazo
- Por padrÃ£o, NÃƒO exige o nÃºmero da NF (coluna NF fica vazia e serÃ¡ preenchida via API da OpenAI)
    Para exigir NF: python scripts/validate_extraction_rules.py --exigir-nf
"""
import os
import argparse
import pandas as pd
import re
import sys
from _init_env import setup_project_path

# Inicializa o ambiente do projeto
setup_project_path()

from core.processor import BaseInvoiceProcessor
from core.models import BoletoData, InvoiceData, DanfeData, OtherDocumentData
from core.diagnostics import ExtractionDiagnostics
from config.settings import (
    DIR_DEBUG_INPUT,
    DIR_DEBUG_OUTPUT,
    DEBUG_CSV_NFSE_SUCESSO,
    DEBUG_CSV_NFSE_FALHA,
    DEBUG_CSV_BOLETO_SUCESSO,
    DEBUG_CSV_BOLETO_FALHA,
    DEBUG_CSV_DANFE_SUCESSO,
    DEBUG_CSV_DANFE_FALHA,
    DEBUG_CSV_OUTROS_SUCESSO,
    DEBUG_CSV_OUTROS_FALHA,
    DEBUG_RELATORIO_QUALIDADE
)


def _nf_candidate_fields_from_obs(obs_interna: str) -> dict:
    """Extrai NF candidata do campo obs_interna (se existir).

    Formato esperado (gerado no pipeline):
        NF_CANDIDATE=12345 (conf=0.82, label=nfse)
    """
    obs = obs_interna or ""
    m = re.search(r"\bNF_CANDIDATE=([0-9]{3,12})\b\s*\(conf=([0-9.]+),\s*([^\)]+)\)", obs)
    if not m:
        return {
            'nf_candidate': "",
            'nf_candidate_confidence': "",
            'nf_candidate_reason': "",
        }
    return {
        'nf_candidate': m.group(1),
        'nf_candidate_confidence': m.group(2),
        'nf_candidate_reason': m.group(3),
    }

def main() -> None:
    """
    Testa as regras de extraÃ§Ã£o nos PDFs da pasta failed_cases_pdf.
    
    Gera CSVs separados:
    - nfse_sucesso.csv / nfse_falha.csv (com coluna motivo_falha)
    - boletos_sucesso.csv / boletos_falha.csv (com coluna motivo_falha)
    - relatorio_qualidade.txt (estatÃ­sticas gerais)
    """
    # Garantia de UTF-8 no Windows (evita UnicodeEncodeError com emojis no print)
    for stream in (getattr(sys, "stdout", None), getattr(sys, "stderr", None)):
        if stream is not None and hasattr(stream, "reconfigure"):
            try:
                stream.reconfigure(encoding="utf-8")
            except Exception:
                pass

    # Parse argumentos
    parser = argparse.ArgumentParser(description='Valida regras de extraÃ§Ã£o de PDFs')
    parser.add_argument('--validar-prazo', action='store_true',
                       help='Valida prazo de 4 dias Ãºteis (ignora por padrÃ£o para docs antigos)')
    parser.add_argument('--exigir-nf', action='store_true',
                        help='Exige numero_nota na NFSe (por padrÃ£o nÃ£o exige no MVP)')
    args = parser.parse_args()
    
    validar_prazo = args.validar_prazo
    exigir_nf = args.exigir_nf
    
    # Cria pasta de saÃ­da se nÃ£o existir
    DIR_DEBUG_OUTPUT.mkdir(parents=True, exist_ok=True)
    
    print("=" * 80)
    print("ðŸ§ª TESTE DE REGRAS - NFSe & BOLETOS")
    print("=" * 80)
    print(f"ðŸ“‚ Lendo: {DIR_DEBUG_INPUT}")
    print(f"ðŸ’¾ Salvando em: {DIR_DEBUG_OUTPUT}")
    if validar_prazo:
        print("â° ValidaÃ§Ã£o de prazo: ATIVA (requer 4 dias Ãºteis)")
    else:
        print("â° ValidaÃ§Ã£o de prazo: DESATIVADA (documentos antigos)")
    if exigir_nf:
        print("ðŸ§¾ NF (numero_nota): EXIGIDA")
    else:
        print("ðŸ§¾ NF (numero_nota): NÃƒO exigida (serÃ¡ preenchida via API da OpenAI)")
    print("=" * 80)

    processor = BaseInvoiceProcessor()
    
    # Listas separadas
    nfse_sucesso = []
    nfse_falha = []
    boletos_sucesso = []
    boletos_falha = []
    danfe_sucesso = []
    danfe_falha = []
    outros_sucesso = []
    outros_falha = []
    
    # Contadores
    count_nfse_ok = 0
    count_nfse_falha = 0
    count_boleto_ok = 0
    count_boleto_falha = 0
    count_danfe_ok = 0
    count_danfe_falha = 0
    count_outros_ok = 0
    count_outros_falha = 0
    count_erro = 0

    if not DIR_DEBUG_INPUT.exists():
        print(f"âŒ Pasta nÃ£o existe: {DIR_DEBUG_INPUT}")
        return

    arquivos = [f for f in os.listdir(DIR_DEBUG_INPUT) if f.lower().endswith('.pdf')]
    
    if not arquivos:
        print("âš ï¸ Nenhum PDF encontrado.")
        return

    print(f"\nðŸ“¦ {len(arquivos)} arquivo(s) encontrado(s)\n")

    for file in arquivos:
        caminho = DIR_DEBUG_INPUT / file
        print(f"{'=' * 80}")
        print(f"âš™ï¸ Processando: {file}")
        
        try:
            result = processor.process(str(caminho))
            
            # === BOLETOS ===
            if isinstance(result, BoletoData):
                eh_sucesso, motivos = ExtractionDiagnostics.classificar_boleto(result, validar_prazo=validar_prazo)
                
                if eh_sucesso:
                    count_boleto_ok += 1
                    # Armazena objeto e dados para uso posterior
                    boletos_sucesso.append({'object': result, **result.__dict__, **_nf_candidate_fields_from_obs(result.obs_interna)})
                    print(f"âœ… BOLETO COMPLETO")
                    print(f"   â€¢ Valor: R$ {result.valor_documento:,.2f}")
                    print(f"   â€¢ Vencimento: {result.vencimento or 'N/A'}")
                    
                else:
                    count_boleto_falha += 1
                    result_dict = result.__dict__
                    result_dict['motivo_falha'] = '|'.join(motivos)
                    result_dict.update(_nf_candidate_fields_from_obs(result_dict.get('obs_interna')))
                    boletos_falha.append(result_dict)
                    print(f"âš ï¸ BOLETO INCOMPLETO: {result_dict['motivo_falha']}")
            
            # === NFSe ===
            elif isinstance(result, InvoiceData):
                eh_sucesso, motivos = ExtractionDiagnostics.classificar_nfse(
                    result,
                    validar_prazo=validar_prazo,
                    exigir_numero_nf=exigir_nf,
                )
                
                if eh_sucesso:
                    count_nfse_ok += 1
                    # Armazena objeto e dados para uso posterior
                    nfse_sucesso.append({'object': result, **result.__dict__, **_nf_candidate_fields_from_obs(result.obs_interna)})
                    print(f"âœ… NFSe COMPLETA")
                    print(f"   â€¢ NÃºmero: {result.numero_nota}")
                    print(f"   â€¢ Valor: R$ {result.valor_total:,.2f}")
                    
                else:
                    count_nfse_falha += 1
                    result_dict = result.__dict__
                    result_dict['motivo_falha'] = '|'.join(motivos)
                    result_dict.update(_nf_candidate_fields_from_obs(result_dict.get('obs_interna')))
                    nfse_falha.append(result_dict)
                    print(f"âš ï¸ NFSe INCOMPLETA: {result_dict['motivo_falha']}")

            # === DANFE ===
            elif isinstance(result, DanfeData):
                # CritÃ©rio mÃ­nimo (sem criar uma regra PAF rÃ­gida ainda): valor>0 e fornecedor
                motivos = []
                if (result.valor_total or 0) <= 0:
                    motivos.append('VALOR_ZERO')
                if not (result.fornecedor_nome and result.fornecedor_nome.strip()):
                    motivos.append('SEM_RAZAO_SOCIAL')
                if not result.cnpj_emitente:
                    motivos.append('SEM_CNPJ')

                eh_sucesso = len(motivos) == 0

                if eh_sucesso:
                    count_danfe_ok += 1
                    danfe_sucesso.append({'object': result, **result.__dict__, **_nf_candidate_fields_from_obs(result.obs_interna)})
                    print(f"âœ… DANFE COMPLETO")
                    print(f"   â€¢ NÃºmero: {result.numero_nota}")
                    print(f"   â€¢ Valor: R$ {result.valor_total:,.2f}")
                else:
                    count_danfe_falha += 1
                    result_dict = result.__dict__
                    result_dict['motivo_falha'] = '|'.join(motivos)
                    result_dict.update(_nf_candidate_fields_from_obs(result_dict.get('obs_interna')))
                    danfe_falha.append(result_dict)
                    print(f"âš ï¸ DANFE INCOMPLETO: {result_dict['motivo_falha']}")

            # === OUTROS ===
            elif isinstance(result, OtherDocumentData):
                motivos = []
                if (result.valor_total or 0) <= 0:
                    motivos.append('VALOR_ZERO')
                if not (result.fornecedor_nome and result.fornecedor_nome.strip()):
                    motivos.append('SEM_RAZAO_SOCIAL')

                eh_sucesso = len(motivos) == 0

                if eh_sucesso:
                    count_outros_ok += 1
                    outros_sucesso.append({'object': result, **result.__dict__, **_nf_candidate_fields_from_obs(result.obs_interna)})
                    print(f"âœ… OUTRO COMPLETO")
                    print(f"   â€¢ Subtipo: {result.subtipo or 'N/A'}")
                    print(f"   â€¢ Valor: R$ {result.valor_total:,.2f}")
                else:
                    count_outros_falha += 1
                    result_dict = result.__dict__
                    result_dict['motivo_falha'] = '|'.join(motivos)
                    result_dict.update(_nf_candidate_fields_from_obs(result_dict.get('obs_interna')))
                    outros_falha.append(result_dict)
                    print(f"âš ï¸ OUTRO INCOMPLETO: {result_dict['motivo_falha']}")
            
            else:
                count_erro += 1
                print(f"â“ TIPO DESCONHECIDO")

        except Exception as e:
            count_erro += 1
            print(f"âŒ ERRO: {e}")

    # === GERAR CSVs NO FORMATO PAF (18 colunas) ===
    print("\n" + "=" * 80)
    print("ðŸ’¾ GERANDO RELATÃ“RIOS (Formato PAF - 18 colunas)")
    print("=" * 80)
    
    # Colunas PAF padrÃ£o (18 colunas conforme POP 4.10)
    COLUNAS_PAF = [
        "DATA", "SETOR", "EMPRESA", "FORNECEDOR", "NF", "EMISSÃƒO",
        "VALOR", "NÂº PEDIDO", "VENCIMENTO", "FORMA PAGTO", "INDEX",
        "DT CLASS", "NÂº FAT", "TP DOC", "TRAT PAF", "LANC SISTEMA",
        "OBSERVAÃ‡Ã•ES", "OBS INTERNA"
    ]
    
    if nfse_sucesso:
        # Converte usando o mÃ©todo to_sheets_row() para formato PAF
        rows_paf = [item['object'].to_sheets_row() for item in nfse_sucesso]
        df_paf = pd.DataFrame(rows_paf, columns=COLUNAS_PAF)
        df_paf.to_csv(DEBUG_CSV_NFSE_SUCESSO, index=False, encoding='utf-8-sig')
        print(f"âœ… {DEBUG_CSV_NFSE_SUCESSO.name} ({len(nfse_sucesso)} registros) - Formato PAF")

        # Export adicional (debug completo, inclui NF candidata)
        df_ok_debug = pd.DataFrame([{k: v for k, v in item.items() if k != 'object'} for item in nfse_sucesso])
        debug_ok_path = DIR_DEBUG_OUTPUT / "nfse_sucesso_debug.csv"
        df_ok_debug.to_csv(debug_ok_path, index=False, encoding='utf-8-sig')
        print(f"â„¹ï¸ {debug_ok_path.name} ({len(nfse_sucesso)} registros) - Debug completo (inclui nf_candidate)")
    
    if nfse_falha:
        # Para falhas, mantÃ©m dados completos + motivo_falha para debug
        df_falha = pd.DataFrame(nfse_falha)
        df_falha.to_csv(DEBUG_CSV_NFSE_FALHA, index=False, encoding='utf-8-sig')
        print(f"âš ï¸ {DEBUG_CSV_NFSE_FALHA.name} ({len(nfse_falha)} registros) - Debug completo")
    
    if boletos_sucesso:
        # Converte usando o mÃ©todo to_sheets_row() para formato PAF
        rows_paf = [item['object'].to_sheets_row() for item in boletos_sucesso]
        df_paf = pd.DataFrame(rows_paf, columns=COLUNAS_PAF)
        df_paf.to_csv(DEBUG_CSV_BOLETO_SUCESSO, index=False, encoding='utf-8-sig')
        print(f"âœ… {DEBUG_CSV_BOLETO_SUCESSO.name} ({len(boletos_sucesso)} registros) - Formato PAF")

        # Export adicional (debug completo, inclui NF candidata)
        df_ok_debug = pd.DataFrame([{k: v for k, v in item.items() if k != 'object'} for item in boletos_sucesso])
        debug_ok_path = DIR_DEBUG_OUTPUT / "boletos_sucesso_debug.csv"
        df_ok_debug.to_csv(debug_ok_path, index=False, encoding='utf-8-sig')
        print(f"â„¹ï¸ {debug_ok_path.name} ({len(boletos_sucesso)} registros) - Debug completo (inclui nf_candidate)")
    
    if boletos_falha:
        # Para falhas, mantÃ©m dados completos + motivo_falha para debug
        df_falha = pd.DataFrame(boletos_falha)
        df_falha.to_csv(DEBUG_CSV_BOLETO_FALHA, index=False, encoding='utf-8-sig')
        print(f"âš ï¸ {DEBUG_CSV_BOLETO_FALHA.name} ({len(boletos_falha)} registros) - Debug completo")

    if danfe_sucesso:
        rows_paf = [item['object'].to_sheets_row() for item in danfe_sucesso]
        df_paf = pd.DataFrame(rows_paf, columns=COLUNAS_PAF)
        df_paf.to_csv(DEBUG_CSV_DANFE_SUCESSO, index=False, encoding='utf-8-sig')
        print(f"âœ… {DEBUG_CSV_DANFE_SUCESSO.name} ({len(danfe_sucesso)} registros) - Formato PAF")

        df_ok_debug = pd.DataFrame([{k: v for k, v in item.items() if k != 'object'} for item in danfe_sucesso])
        debug_ok_path = DIR_DEBUG_OUTPUT / "danfe_sucesso_debug.csv"
        df_ok_debug.to_csv(debug_ok_path, index=False, encoding='utf-8-sig')
        print(f"â„¹ï¸ {debug_ok_path.name} ({len(danfe_sucesso)} registros) - Debug completo (inclui nf_candidate)")

    if danfe_falha:
        df_falha = pd.DataFrame(danfe_falha)
        df_falha.to_csv(DEBUG_CSV_DANFE_FALHA, index=False, encoding='utf-8-sig')
        print(f"âš ï¸ {DEBUG_CSV_DANFE_FALHA.name} ({len(danfe_falha)} registros) - Debug completo")

    if outros_sucesso:
        rows_paf = [item['object'].to_sheets_row() for item in outros_sucesso]
        df_paf = pd.DataFrame(rows_paf, columns=COLUNAS_PAF)
        df_paf.to_csv(DEBUG_CSV_OUTROS_SUCESSO, index=False, encoding='utf-8-sig')
        print(f"âœ… {DEBUG_CSV_OUTROS_SUCESSO.name} ({len(outros_sucesso)} registros) - Formato PAF")

        df_ok_debug = pd.DataFrame([{k: v for k, v in item.items() if k != 'object'} for item in outros_sucesso])
        debug_ok_path = DIR_DEBUG_OUTPUT / "outros_sucesso_debug.csv"
        df_ok_debug.to_csv(debug_ok_path, index=False, encoding='utf-8-sig')
        print(f"â„¹ï¸ {debug_ok_path.name} ({len(outros_sucesso)} registros) - Debug completo (inclui nf_candidate)")

    if outros_falha:
        df_falha = pd.DataFrame(outros_falha)
        df_falha.to_csv(DEBUG_CSV_OUTROS_FALHA, index=False, encoding='utf-8-sig')
        print(f"âš ï¸ {DEBUG_CSV_OUTROS_FALHA.name} ({len(outros_falha)} registros) - Debug completo")

    # === RELATÃ“RIO ===
    dados_relatorio = {
        'total': len(arquivos),
        'nfse_ok': count_nfse_ok,
        'nfse_falha': count_nfse_falha,
        'boleto_ok': count_boleto_ok,
        'boleto_falha': count_boleto_falha,
        'danfe_ok': count_danfe_ok,
        'danfe_falha': count_danfe_falha,
        'outros_ok': count_outros_ok,
        'outros_falha': count_outros_falha,
        'erros': count_erro,
        'nfse_falhas_detalhe': nfse_falha,
        'boleto_falhas_detalhe': boletos_falha,
        'danfe_falhas_detalhe': danfe_falha,
        'outros_falhas_detalhe': outros_falha,
    }
    
    # Usa o mÃ³dulo centralizado de diagnÃ³sticos
    ExtractionDiagnostics.salvar_relatorio(dados_relatorio, DEBUG_RELATORIO_QUALIDADE)
    print(f"ðŸ“Š {DEBUG_RELATORIO_QUALIDADE.name}")
    
    # === RESUMO ===
    print("\n" + "=" * 80)
    print("ðŸ“Š RESUMO FINAL")
    print("=" * 80)
    print(f"\nðŸ“ˆ NFSe: {count_nfse_ok} OK / {count_nfse_falha} Falhas")
    print(f"ðŸ“ˆ Boletos: {count_boleto_ok} OK / {count_boleto_falha} Falhas")
    print(f"ðŸ“ˆ DANFE: {count_danfe_ok} OK / {count_danfe_falha} Falhas")
    print(f"ðŸ“ˆ Outros: {count_outros_ok} OK / {count_outros_falha} Falhas")
    print(f"âŒ Erros: {count_erro}")
    print("\n" + "=" * 80)

if __name__ == "__main__":
    main()